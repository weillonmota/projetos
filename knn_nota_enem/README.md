# ü§ñ Prevendo Notas do ENEM com Machine Learning

Bem-vindo! Este projeto √© um guia pr√°tico que demonstra como usar dados para treinar um modelo de Machine Learning otimizado capaz de prever as notas de um estudante no ENEM.

Utilizamos uma t√©cnica chamada k-Nearest Neighbors (k-NN), ou "k-Vizinhos Mais Pr√≥ximos", e aplicamos a Normaliza√ß√£o de Features (StandardScaler) e os Pesos por Dist√¢ncia (weights='distance') para aumentar a precis√£o e a qualidade da previs√£o.

O objetivo √© criar um material did√°tico, explicando cada passo do processo de forma clara e simples, desde a coleta dos dados brutos at√© o salvamento de um modelo robusto e pronto para uso em uma aplica√ß√£o web.

## üìÇ Estrutura do Projeto

O c√≥digo est√° organizado em um notebook Jupyter (`etl.ipynb`) e dividido em quatro etapas principais:

1.  **Configura√ß√£o**: Onde preparamos nosso ambiente e definimos as regras do jogo.
2.  **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)**: A fase de "faxina", onde limpamos e organizamos os dados.
3.  **Otimiza√ß√£o do k-NN**: O cora√ß√£o do projeto, onde testamos o melhor hiperpar√¢metro `k` usando uma t√©cnica de pesos por dist√¢ncia para previs√µes mais inteligentes.
4.  **Treinamento Final e Salvamento de Artefatos**: Onde consolidamos o aprendizado e salvamos todos os arquivos necess√°rios para a aplica√ß√£o (`modelo.joblib`, `scaler.joblib`, `colunas.json` e `y_train_data.csv`).

---
## ü§î Como o Programa Funciona? Um Guia Passo a Passo

### Etapa 1: Configura√ß√£o e Constantes

Antes de come√ßar qualquer projeto de programa√ß√£o, √© uma boa pr√°tica organizar as ferramentas. Nesta primeira c√©lula do c√≥digo, √© preciso:
- **Importamos as bibliotecas**: Ferramentas como `pandas` (para mexer com tabelas), `scikit-learn` (para Machine Learning) e `StandardScaler`para normalizar nossos dados.
- **Centralizamos as informa√ß√µes**: Definimos nomes de arquivos e colunas em um √∫nico lugar. Isso √© como ter uma "lista de compras" antes de ir ao mercado e se precisarmos mudar algo, sabemos exatamente onde olhar. Temos arquivos: `ARQUIVO_SCALER` (para salvar nosso normalizador) e `ARQUIVO_Y_TRAIN` (para salvar os dados de treino, permitindo a compara√ß√£o com os vizinhos no dashboard).

```python
# Importa√ß√£o de bibliotecas essenciais
import pandas as pd
import joblib
import json
import os
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler  # <-- Para normalizar os dados

# --- ARQUIVOS E CAMINHOS ---
ARQUIVOS_ENEM = ['MICRODADOS_ENEM_2021.csv', 'MICRODADOS_ENEM_2022.csv', 'MICRODADOS_ENEM_2023.csv']
ARQUIVO_DADOS_CEARA = 'dados_ceara.csv'
ARQUIVO_MODELO = 'modelo_knn.joblib'
ARQUIVO_COLUNAS = 'colunas_modelo.json'
ARQUIVO_SCALER = 'scaler.joblib'       # <-- Arquivo para o normalizador
ARQUIVO_Y_TRAIN = 'y_train_data.csv'  # <-- Arquivo para os dados de treino

# --- COLUNAS DO DATASET ---
COLUNAS_ALVO = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']
COLUNAS_FEATURES = ['Q006', 'Q002', 'TP_ESCOLA', 'TP_COR_RACA', 'SG_UF_ESC']
COLUNAS_DESEJADAS = ['NU_ANO'] + COLUNAS_ALVO + COLUNAS_FEATURES

# --- PAR√ÇMETROS DO MODELO ---
ESTADO_ALEATORIO = 42 
TAMANHO_TESTE = 0.2  

print("‚úÖ M√≥dulo de Configura√ß√£o (v2) carregado com sucesso!")
```
> **Sa√≠da:**
> ```
> ‚úÖ M√≥dulo de Configura√ß√£o carregado com sucesso!
> ```

### Etapa 2: A Faxina dos Dados (ETL)

Os dados brutos do ENEM s√£o gigantescos e um pouco bagun√ßados. Para que nosso modelo consiga aprender algo √∫til, precisamos primeiro organizar a casa. O processo de ETL faz exatamente isso:

1.  **Extrair**: Lemos os arquivos CSV (um para cada ano). Para n√£o sobrecarregar a mem√≥ria do computador, lemos apenas as colunas que definimos no Bloco 1 (`COLUNAS_DESEJADAS`).
   
2.  **Transformar**: Aqui acontece a m√°gica da limpeza. N√≥s:
    - **Removemos** todas as linhas que t√™m alguma informa√ß√£o faltando (ex: dropna()). Um aluno sem nota n√£o pode ser usado para treinar o modelo.
    - **Filtramos** os dados para manter apenas os registros de estudantes do Cear√° (CE), conforme definido em `estado_filtro`.
    - **Tratamos erros** de codifica√ß√£o, tentando ler os arquivos em latin-1 e, se falhar, mudando para utf-8.
      
3.  **Carregar**: Juntamos todos os dados limpos de diferentes anos em uma √∫nica tabela e a salvamos como `dados_ceara.csv`. Ter esse arquivo limpo economiza muito tempo, pois n√£o precisamos repetir essa faxina toda vez que rodamos o projeto.

**‚ö†Ô∏è Observa√ß√£o Importante sobre a Amostragem:**  
*Para diminuir o universo de dados e focar a an√°lise em um contexto espec√≠fico, optamos por limitar a amostragem a estudantes do Cear√° (CE). No entanto, para compensar essa redu√ß√£o e aumentar a robustez do modelo, inclu√≠mos um per√≠odo maior de tempo, utilizando as notas do ENEM de tr√™s anos (2021 a 2023). O objetivo desse balanceamento √© fornecer uma base s√≥lida o suficiente para melhorar o √≠ndice MAE (Erro M√©dio Absoluto), a m√©trica de erro que ser√° detalhada na se√ß√£o de treinamento do modelo k-NN.* 

Base de Dados: Microdados do ENEM  
Local de Acesso: [https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem)

```python
def executar_etl(lista_arquivos: list, colunas: list, estado_filtro: str = 'CE') -> pd.DataFrame | None:
    """
    L√™, limpa, filtra e combina m√∫ltiplos arquivos CSV do ENEM.
    - Extra√ß√£o: L√™ apenas as colunas desejadas para otimizar o uso de mem√≥ria.
    - Transforma√ß√£o: Remove linhas com dados faltantes e filtra pelo estado.
    - Carga: Consolida os dados de todos os arquivos em um √∫nico DataFrame.
    """
    print(f"\n--- üöÄ Iniciando processo de ETL para o estado: {estado_filtro} ---")
    dataframes = []

    for arquivo in lista_arquivos:
        if not os.path.exists(arquivo):
            print(f"‚ö†Ô∏è AVISO: Arquivo '{arquivo}' n√£o encontrado. Pulando...")
            continue
        try:
            print(f"Processando: {arquivo}...")
            # Tentando com encoding 'latin-1' como no original
            try:
                df = pd.read_csv(arquivo, sep=';', encoding='latin-1', usecols=colunas)
            except UnicodeDecodeError:
                print(f"-> Falha no latin-1. Tentando 'utf-8' para {arquivo}...")
                df = pd.read_csv(arquivo, sep=';', encoding='utf-8', usecols=colunas)
                
            df.dropna(inplace=True)
            df_estado = df[df['SG_UF_ESC'] == estado_filtro]
            
            if not df_estado.empty:
                dataframes.append(df_estado)
                print(f"-> {len(df_estado)} linhas v√°lidas encontradas.")
            else:
                print(f"-> Nenhuma linha v√°lida para o Cear√° neste arquivo.")
                
        except Exception as e:
            print(f"‚ùå ERRO inesperado ao processar '{arquivo}': {e}")

    if not dataframes:
        print("\n‚ùå ETL falhou. Nenhum DataFrame foi processado.")
        return None

    df_final = pd.concat(dataframes, ignore_index=True)
    print(f"\n‚úÖ ETL Conclu√≠do. DataFrame final criado com {len(df_final)} linhas.")
    df_final.to_csv(ARQUIVO_DADOS_CEARA, index=False)
    print(f"üíæ Dados limpos salvos em '{ARQUIVO_DADOS_CEARA}'.")
    return df_final

# Executa a fun√ß√£o
dados_limpos_ceara = executar_etl(lista_arquivos=ARQUIVOS_ENEM, colunas=COLUNAS_DESEJADAS)
```
> **Sa√≠da:**
> ```
>--- üöÄ Iniciando processo de ETL para o estado: CE ---
Processando: MICRODADOS_ENEM_2021.csv...
-> 58503 linhas v√°lidas encontradas.
Processando: MICRODADOS_ENEM_2022.csv...
-> 71340 linhas v√°lidas encontradas.
Processando: MICRODADOS_ENEM_2023.csv...
-> 74319 linhas v√°lidas encontradas.

‚úÖ ETL Conclu√≠do. DataFrame final criado com 204162 linhas.
üíæ Dados limpos salvos em 'dados_ceara.csv'.
> ```

### Etapa 3: Ensinando o Computador a "Adivinhar" com k-NN

Agora chegamos √† parte mais interessante: como o modelo de Machine Learning realmente funciona? Usamos o algoritmo **k-Nearest Neighbors (k-NN)**, que √© surpreendentemente intuitivo.

#### Uma Analogia Simples para Entender o k-NN

Imagine que voc√™ quer prever o pre√ßo de uma casa, mas n√£o tem ideia de como fazer isso. Uma abordagem simples seria:
1.  Encontrar as **3 casas mais parecidas** com a sua na mesma vizinhan√ßa (com tamanho, n√∫mero de quartos e idade similares).
2.  Perguntar o pre√ßo de cada uma dessas 3 casas.
3.  Calcular a **m√©dia de pre√ßo** dessas 3 casas.
4.  Pronto! Essa m√©dia √© a sua "previs√£o" para o pre√ßo da sua casa.

O k-NN faz exatamente isso, mas para prever as notas do ENEM. Ele n√£o prev√™ o pre√ßo de uma casa, mas sim as notas de um aluno (`NU_NOTA_CN`, `NU_NOTA_MT`, etc.).

#### Como o k-NN Foi Implementado Neste Projeto?

A ferramenta que usamos para isso √© o KNeighborsRegressor do scikit-learn . O nome "Regressor" indica que ele serve para prever n√∫meros cont√≠nuos (como uma nota de 0 a 1000), e n√£o para classificar em categorias (como "aprovado" ou "reprovado").


Para o modelo funcionar, n√≥s definimos:

1.  **Definindo os "Vizinhos" (as `COLUNAS_FEATURES`)**: Para o nosso modelo, um "vizinho" √© um outro estudante com um perfil socioecon√¥mico parecido. N√≥s dizemos ao algoritmo para comparar os alunos com base em caracter√≠sticas como:
    - `Q006`: A renda familiar.
    - `Q002`: A escolaridade da m√£e.
    - `TP_ESCOLA`: O tipo de escola (p√∫blica ou privada).

2.  **O "k" da Quest√£o (A Otimiza√ß√£o do Hiperpar√¢metro)**: Na nossa analogia, usamos 3 casas. Mas por que 3? Por que n√£o 5, 10 ou 20? Esse n√∫mero √© o `k`, e escolher o `k` certo √© fundamental.
    - Se `k` for **muito pequeno** (ex: `k=1`), o modelo fica "superespecialista". Ele baseia a previs√£o em um √∫nico vizinho, o que pode ser muito inst√°vel e levar a erros.
    - Se `k` for **muito grande** (ex: `k=100`), o modelo fica "gen√©rico demais". Ele considera tantos vizinhos que a previs√£o se torna uma m√©dia muito geral, perdendo as particularidades.

    A c√©lula **"Otimiza√ß√£o do Hiperpar√¢metro 'k'"** automatiza essa busca. Ela testa v√°rios valores para `k` (3, 5, 7, 9, etc.) e, para cada um, calcula o **Erro M√©dio Absoluto (MAE)**. O MAE nos diz, em m√©dia, qu√£o longe as previs√µes do modelo ficaram das notas reais. O valor de `k` que gerar o menor erro √© o campe√£o!

3.  **O Modelo em A√ß√£o (`KNeighborsRegressor`)**: A ferramenta que usamos para isso √© o `KNeighborsRegressor` do `scikit-learn`. O nome "Regressor" indica que ele serve para prever n√∫meros cont√≠nuos (como uma nota de 0 a 1000), e n√£o para classificar em categorias (como "aprovado" ou "reprovado").

Para garantir que o modelo seja justo e inteligente, aplicamos essas t√©cnicas:
4. **Normaliza√ß√£o de Features** (StandardScaler): Nossos dados (COLUNAS_FEATURES) t√™m escalas muito diferentes (ex: Renda, com muitas categorias, vs. Tipo de Escola, com apenas duas). Para que o modelo calcule a "dist√¢ncia" de forma justa, sem que uma feature domine a outra, n√≥s normalizamos os dados. O StandardScaler faz com que todas as features tenham a mesma escala de import√¢ncia.

5. **Pesos por Dist√¢ncia** (weights='distance'): Em vez de tratar todos os "vizinhos" como iguais, usamos weights='distance'. Isso diz ao modelo para dar mais peso aos vizinhos que s√£o extremamente parecidos e menos peso aos que s√£o apenas "mais ou menos" parecidos. Isso resulta em uma previs√£o muito mais precisa e sens√≠vel √†s pequenas diferen√ßas de perfil.

A fun√ß√£o `encontrar_melhor_k` no c√≥digo abaixo implementa tudo isso:

```python
def encontrar_melhor_k(df: pd.DataFrame, valores_k: list) -> int:
    """
    Testa diferentes valores de 'k' para o k-NN (usando weights='distance')
    e retorna o que minimiza o erro.
    """
    print("\n--- üß† Buscando o melhor valor de 'k' (com StandardScaler e weights='distance') ---")
    if df is None:
        print("‚ùå DataFrame de entrada √© inv√°lido. Abortando a otimiza√ß√£o.")
        return 0

    X = pd.get_dummies(df[COLUNAS_FEATURES], drop_first=True)
    y = df[COLUNAS_ALVO]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TAMANHO_TESTE, random_state=ESTADO_ALEATORIO
    )

    print("Aplicando StandardScaler (normaliza√ß√£o)...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print("-> Dados normalizados.")
    
    print("Iniciando os testes (esta etapa pode demorar)...")
    resultados_mae = {}
    for k in valores_k:
        print(f"   - Processando k = {k}...")
        
        # --- MODIFICA√á√ÉO PRINCIPAL AQUI ---
        # Adicionamos weights='distance'
        modelo = KNeighborsRegressor(
            n_neighbors=k, 
            weights='distance', # <-- A MUDAN√áA
            n_jobs=-1
        ) 
        # ------------------------------------
        
        modelo.fit(X_train_scaled, y_train)
        y_pred = modelo.predict(X_test_scaled) 

        mae_geral = mean_absolute_error(y_test, y_pred)
        resultados_mae[k] = mae_geral
        
        print(f"     -> Teste k={k} conclu√≠do! MAE Geral: {mae_geral:.4f}")

    if not resultados_mae:
        print("‚ùå Nenhum resultado foi calculado. Verifique os dados de entrada.")
        return 0
        
    melhor_k = min(resultados_mae, key=resultados_mae.get)
    print("\n   -> Todos os testes foram conclu√≠dos.")
    # O MAE pode ser um pouco diferente agora, o que √© normal
    print(f"\n‚úÖ Otimiza√ß√£o Finalizada. Melhor valor encontrado: k = {melhor_k}")
    return melhor_k

# --- Execu√ß√£o da Fun√ß√£o ---
if 'dados_limpos_ceara' in locals() and dados_limpos_ceara is not None:
    valores_k_para_testar = [3, 5, 7, 9, 11, 13, 15, 17, 19]
    melhor_k = encontrar_melhor_k(dados_limpos_ceara, valores_k_para_testar)
else:
    print("‚ùå ERRO: A vari√°vel 'dados_limpos_ceara' n√£o foi encontrada ou est√° vazia.")
    print("‚û°Ô∏è Por favor, execute a c√©lula de ETL (Bloco 2) primeiro.")
    melhor_k = 0√£o foi encontrada. Execute a c√©lula de ETL primeiro.")
```

> **Sa√≠da:**
> ```
> --- üß† Buscando o melhor valor de 'k' (com StandardScaler e weights='distance') ---
Aplicando StandardScaler (normaliza√ß√£o)...
-> Dados normalizados.
Iniciando os testes (esta etapa pode demorar)...
   - Processando k = 3...
     -> Teste k=3 conclu√≠do! MAE Geral: 96.4514
   - Processando k = 5...
     -> Teste k=5 conclu√≠do! MAE Geral: 91.9658
   - Processando k = 7...
     -> Teste k=7 conclu√≠do! MAE Geral: 91.3061
   - Processando k = 9...
     -> Teste k=9 conclu√≠do! MAE Geral: 89.2031
   - Processando k = 11...
     -> Teste k=11 conclu√≠do! MAE Geral: 88.3925
   - Processando k = 13...
     -> Teste k=13 conclu√≠do! MAE Geral: 87.6376
   - Processando k = 15...
     -> Teste k=15 conclu√≠do! MAE Geral: 87.4599
   - Processando k = 17...
     -> Teste k=17 conclu√≠do! MAE Geral: 87.2849
   - Processando k = 19...
     -> Teste k=19 conclu√≠do! MAE Geral: 86.8260

   -> Todos os testes foram conclu√≠dos.

‚úÖ Otimiza√ß√£o Finalizada. Melhor valor encontrado: k = 19
> ```

### Etapa 4: Treinamento e Salvamento do Modelo Final

Depois de todo o trabalho de limpeza (Etapa 2) e otimiza√ß√£o (Etapa 3), descobrimos que k=19 √© o nosso n√∫mero ideal de vizinhos.

Agora, estamos prontos para treinar o modelo uma √∫ltima vez e salv√°-lo. Esta etapa √© crucial, pois ela gera os "artefatos" ‚Äî os arquivos finais que nosso dashboard (ou qualquer outra aplica√ß√£o) usar√° para fazer previs√µes reais.

N√≥s n√£o salvamos apenas o modelo, mas quatro arquivos essenciais:

1. `modelo_knn.joblib`: Este √© o "c√©rebro" do nosso sistema. √â o modelo k-NN treinado com o k=19 e weights='distance'.

2. `scaler.joblib`: Este √© o "normalizador" oficial. Ele salvou a m√©dia e o desvio padr√£o dos nossos dados de treino. Qualquer nova informa√ß√£o (como a de um usu√°rio no dashboard) deve ser normalizada por este exato scaler para que a previs√£o funcione.

3. `colunas_modelo.json`: Este √© o "manual de instru√ß√µes" do modelo. Ele salva a lista exata de colunas (e a ordem delas) que o modelo foi treinado para receber. Isso evita erros se o usu√°rio inserir dados em ordem diferente.

4. `y_train_data.csv`: Este √© o nosso "banco de dados dos vizinhos". Ele cont√©m as notas reais de todos os alunos que o modelo usou para treinar. O dashboard usar√° este arquivo para encontrar as notas m√≠nimas, m√°ximas e m√©dias dos vizinhos e compar√°-las com a previs√£o.

A fun√ß√£o treinar_e_salvar_modelo_final faz exatamente isso: ela treina o modelo com os dados de treino e salva esses quatro artefatos no disco.

```python
def treinar_e_salvar_modelo_final(df: pd.DataFrame, k: int):
    """
    Treina o modelo k-NN com 'weights=distance' e salva todos os artefatos.
    """
    print(f"\n--- üöÇ Treinando e salvando o modelo final com k = {k} e weights='distance' ---")
    if df is None or k == 0:
        print("‚ùå Dados ou valor de 'k' inv√°lidos. Abortando treinamento.")
        return

    # 1. Preparar os dados
    X = pd.get_dummies(df[COLUNAS_FEATURES], drop_first=True)
    y = df[COLUNAS_ALVO]
    
    X_train, _, y_train, _ = train_test_split(
        X, y, test_size=TAMANHO_TESTE, random_state=ESTADO_ALEATORIO
    )

    # 2. StandardScaler
    print("Aplicando e salvando o StandardScaler...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    print("-> Scaler treinado.")

    # 3. Treina o modelo final
    print("Treinando o modelo k-NN final...")
    
    # --- MODIFICA√á√ÉO PRINCIPAL AQUI ---
    modelo_final = KNeighborsRegressor(
        n_neighbors=k, 
        weights='distance', # <-- A MUDAN√áA
        n_jobs=-1
    )
    # ------------------------------------
    
    modelo_final.fit(X_train_scaled, y_train) 
    print("-> Modelo treinado.")

    # 4. Salvando os artefatos
    print("Salvando artefatos no disco...")
    
    joblib.dump(modelo_final, ARQUIVO_MODELO)
    joblib.dump(scaler, ARQUIVO_SCALER) 
    
    with open(ARQUIVO_COLUNAS, 'w') as f:
        json.dump(X_train.columns.tolist(), f) 

    # Salva o y_train (sem mudan√ßas aqui)
    y_train.reset_index(drop=True).to_csv(ARQUIVO_Y_TRAIN, index=False)

    print(f"‚úÖ Modelo final treinado com sucesso!")
    print(f"üíæ Modelo salvo em: '{ARQUIVO_MODELO}' (com weights='distance')")
    print(f"üíæ Scaler salvo em: '{ARQUIVO_SCALER}'") 
    print(f"üíæ Colunas salvas em: '{ARQUIVO_COLUNAS}'")
    print(f"üíæ Dados de treino (y_train) salvos em: '{ARQUIVO_Y_TRAIN}'")
    print("\n--- üöÄ PROJETO CONCLU√çDO ---")

# --- Execu√ß√£o da Fun√ß√£o ---
if 'dados_limpos_ceara' in locals() and 'melhor_k' in locals():
    if dados_limpos_ceara is not None and melhor_k > 0:
        treinar_e_salvar_modelo_final(dados_limpos_ceara, melhor_k)
    else:
        print("‚ùå ERRO: 'dados_limpos_ceara' ou 'melhor_k' s√£o inv√°lidos. Verifique os blocos anteriores.")
else:
    print("‚ùå ERRO: Vari√°veis 'dados_limpos_ceara' ou 'melhor_k' n√£o encontradas. Execute os Blocos 2 e 3.")
```
> **Sa√≠da:**
> ```
>--- üöÇ Treinando e salvando o modelo final com k = 19 e weights='distance' ---
Aplicando e salvando o StandardScaler...
-> Scaler treinado.
Treinando o modelo k-NN final...
-> Modelo treinado.
Salvando artefatos no disco...
‚úÖ Modelo final treinado com sucesso!
üíæ Modelo salvo em: 'modelo_knn.joblib' (com weights='distance')
üíæ Scaler salvo em: 'scaler.joblib'
üíæ Colunas salvas em: 'colunas_modelo.json'
üíæ Dados de treino (y_train) salvos em: 'y_train_data.csv'
--- üöÄ PROJETO CONCLU√çDO ---
> ```

## ‚ú® Sess√£o B√¥nus: Aplica√ß√£o Pr√°tica em um Dashboard Interativo  

Ap√≥s todo o trabalho de limpeza, otimiza√ß√£o e treinamento, o produto final n√£o √© apenas o c√≥digo, mas o modelo salvo (`modelo_knn.joblib`) e seu manual (`colunas_modelo.json`), prontos para serem usados.

O Dashboard interativo √© a prova de conceito de que nosso modelo funciona na pr√°tica. Ele permite que qualquer pessoa interaja com o "c√©rebro" do Machine Learning que acabamos de criar.

## üìä Objetivo do Dashboard  
O objetivo √© transformar a l√≥gica complexa do nosso c√≥digo Python em uma ferramenta acess√≠vel e visual. O dashboard, implementado no arquivo `dashboard.py` (em anexo no reposit√≥rio), faz o seguinte:

- Carrega os 4 artefatos (modelo_knn.joblib, scaler.joblib, colunas_modelo.json e y_train_data.csv).
- Coleta o Perfil do Usu√°rio atrav√©s de caixas de sele√ß√£o (Renda, Escolaridade da M√£e, etc.).
- Prepara os dados do usu√°rio: Converte as escolhas em um formato que o modelo entenda (usando `get_dummies` e `reindex` com as colunas salvas).
- Normaliza os dados: Aplica o `scaler.joblib` nos dados do usu√°rio.
- Realiza a Previs√£o: Passa os dados normalizados para o `modelo_knn.joblib` e obt√©m as notas previstas.
- Compara com os Vizinhos: O dashboard usa a previs√£o para encontrar os `k` vizinhos no arquivo `y_train_data.csv` e exibe a compara√ß√£o da nota do aluno com a m√©dia, m√≠nima e m√°xima do seu grupo de perfil similar.

## üé® Sobre o Streamlit  
Para construir o dashboard, utilizamos a biblioteca Streamlit.

O Streamlit √© uma ferramenta de c√≥digo aberto que permite transformar scripts de an√°lise de dados e Machine Learning em aplicativos da web interativos e bonitos com pouqu√≠ssimas linhas de c√≥digo. √â a solu√ß√£o perfeita para demonstrar o potencial do nosso modelo sem a necessidade de aprender tecnologias complexas de desenvolvimento web (como HTML, CSS e JavaScript). Ele lida com a interatividade, o layout e a implanta√ß√£o de forma quase m√°gica.  

## üéØ Veja o Modelo em A√ß√£o  
Voc√™ pode interagir e testar o poder de previs√£o do modelo k-NN treinado neste projeto atrav√©s do link de implanta√ß√£o:  

üëâ[Veja o projeto clicando aqui!](https://enem-knn.streamlit.app/)

## üöÄ Conclus√£o  
Este projeto transforma dados brutos em intelig√™ncia acion√°vel. Seguindo estes passos, constru√≠mos um sistema que aprendeu a encontrar padr√µes no perfil dos estudantes e, com base neles, fazer previs√µes sobre seu desempenho no ENEM. O uso do k-NN mostra como conceitos de "similaridade" e "vizinhan√ßa" podem ser ferramentas poderosas no mundo do Machine Learning.

## üßë‚Äçüíª Autor

Projeto criado por **[Weillon Mota]**  
üì´ [weillonmota@gmail.com]  
üîó [linkedin.com/in/weillonmota](https://linkedin.com/in/weillonmota)
