# ü§ñ Prevendo Notas do ENEM com Machine Learning

Bem-vindo! Este projeto √© um guia pr√°tico que demonstra como usar dados para treinar um modelo de Machine Learning capaz de prever as notas de um estudante no ENEM. Utilizamos uma t√©cnica chamada **k-Nearest Neighbors (k-NN)**, ou "k-Vizinhos Mais Pr√≥ximos", para realizar essa tarefa.

O objetivo √© criar um material did√°tico, explicando cada passo do processo de forma clara e simples, desde a coleta dos dados brutos at√© o salvamento de um modelo pronto para uso.

## üìÇ Estrutura do Projeto

O c√≥digo est√° organizado em um notebook Jupyter (`etl.ipynb`) e dividido em quatro etapas principais:

1.  **Configura√ß√£o**: Onde preparamos nosso ambiente e definimos as regras do jogo.
2.  **ETL (Extra√ß√£o, Transforma√ß√£o e Carga)**: A fase de "faxina", onde limpamos e organizamos os dados.
3.  **Otimiza√ß√£o do k-NN**: O cora√ß√£o do projeto, onde ensinamos o modelo a aprender com os dados.
4.  **Treinamento Final**: Onde consolidamos o aprendizado e salvamos nosso modelo inteligente.

---
## ü§î Como o Programa Funciona? Um Guia Passo a Passo

### Etapa 1: Configura√ß√£o e Constantes

Antes de come√ßar qualquer projeto de programa√ß√£o, √© uma boa pr√°tica organizar as ferramentas. Nesta primeira c√©lula do c√≥digo, n√≥s:
- **Importamos as bibliotecas**: Ferramentas como `pandas` (para mexer com tabelas) e `scikit-learn` (para Machine Learning).
- **Centralizamos as informa√ß√µes**: Definimos nomes de arquivos e colunas em um √∫nico lugar. Isso √© como ter uma "lista de compras" antes de ir ao mercado; se precisarmos mudar algo, sabemos exatamente onde olhar.

```python
# Importa√ß√£o de bibliotecas essenciais
import pandas as pd
import joblib
import json
import os
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error

# --- ARQUIVOS E CAMINHOS ---
ARQUIVOS_ENEM = ['MICRODADOS_ENEM_2021.csv', 'MICRODADOS_ENEM_2022.csv', 'MICRODADOS_ENEM_2023.csv']
ARQUIVO_DADOS_CEARA = 'dados_ceara.csv'
ARQUIVO_MODELO = 'modelo_knn.joblib'
ARQUIVO_COLUNAS = 'colunas_modelo.json'

# --- COLUNAS DO DATASET ---
# Colunas que ser√£o o alvo da nossa previs√£o (target)
COLUNAS_ALVO = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']
# Colunas que usaremos para fazer a previs√£o (features)
COLUNAS_FEATURES = ['Q006', 'Q002', 'TP_ESCOLA', 'TP_COR_RACA', 'SG_UF_ESC']
# Lista completa de colunas a serem lidas dos arquivos originais
COLUNAS_DESEJADAS = ['NU_ANO'] + COLUNAS_ALVO + COLUNAS_FEATURES

# --- PAR√ÇMETROS DO MODELO ---
ESTADO_ALEATORIO = 42 # Garante que a divis√£o dos dados seja sempre a mesma
TAMANHO_TESTE = 0.2  # Define que 20% dos dados ser√£o usados para teste

print("‚úÖ M√≥dulo de Configura√ß√£o carregado com sucesso!")
```
> **Sa√≠da:**
> ```
> ‚úÖ M√≥dulo de Configura√ß√£o carregado com sucesso!
> ```

### Etapa 2: A Faxina dos Dados (ETL)

Os dados brutos do ENEM s√£o gigantescos e um pouco bagun√ßados. Para que nosso modelo consiga aprender algo √∫til, precisamos primeiro organizar a casa. O processo de ETL faz exatamente isso:

1.  **Extrair**: Lemos os arquivos CSV do ENEM (`MICRODADOS_ENEM_2021.csv`, etc.). Para n√£o sobrecarregar a mem√≥ria do computador, pegamos apenas as colunas que nos interessam.
2.  **Transformar**: Aqui acontece a m√°gica da limpeza. N√≥s:
    - Removemos todas as linhas que t√™m alguma informa√ß√£o faltando (como uma nota em branco).
    - Filtramos os dados para manter apenas os registros de estudantes do Cear√° (`CE`).
3.  **Carregar**: Juntamos todos os dados limpos de diferentes anos em uma √∫nica tabela e a salvamos como `dados_ceara.csv`. Ter esse arquivo limpo economiza muito tempo, pois n√£o precisamos repetir essa faxina toda vez que rodamos o projeto.


```python
def executar_etl(lista_arquivos: list, colunas: list, estado_filtro: str = 'CE') -> pd.DataFrame | None:
    """
    L√™, limpa, filtra e combina m√∫ltiplos arquivos CSV do ENEM.
    - Extra√ß√£o: L√™ apenas as colunas desejadas para otimizar o uso de mem√≥ria.
    - Transforma√ß√£o: Remove linhas com dados faltantes e filtra pelo estado.
    - Carga: Consolida os dados de todos os arquivos em um √∫nico DataFrame.
    """
    print(f"\n--- üöÄ Iniciando processo de ETL para o estado: {estado_filtro} ---")
    dataframes = []

    for arquivo in lista_arquivos:
        if not os.path.exists(arquivo):
            print(f"‚ö†Ô∏è AVISO: Arquivo '{arquivo}' n√£o encontrado. Pulando...")
            continue
        try:
            print(f"Processando: {arquivo}...")
            df = pd.read_csv(arquivo, sep=';', encoding='latin-1', usecols=colunas)
            df.dropna(inplace=True)
            df_estado = df[df['SG_UF_ESC'] == estado_filtro]
            if not df_estado.empty:
                dataframes.append(df_estado)
                print(f"-> {len(df_estado)} linhas v√°lidas encontradas.")
            else:
                print("-> Nenhuma linha v√°lida para o Cear√° neste arquivo.")
        except Exception as e:
            print(f"‚ùå ERRO inesperado ao processar '{arquivo}': {e}")

    if not dataframes:
        print("\n‚ùå ETL falhou. Nenhum DataFrame foi processado.")
        return None

    df_final = pd.concat(dataframes, ignore_index=True)
    print(f"\n‚úÖ ETL Conclu√≠do. DataFrame final criado com {len(df_final)} linhas.")
    df_final.to_csv(ARQUIVO_DADOS_CEARA, index=False)
    print(f"üíæ Dados limpos salvos em '{ARQUIVO_DADOS_CEARA}'.")
    return df_final

# Executa a fun√ß√£o
dados_limpos_ceara = executar_etl(lista_arquivos=ARQUIVOS_ENEM, colunas=COLUNAS_DESEJADAS)
```
> **Sa√≠da:**
> ```
> --- üöÄ Iniciando processo de ETL para o estado: CE ---
> Processando: MICRODADOS_ENEM_2021.csv...
> -> 58503 linhas v√°lidas encontradas.
> Processando: MICRODADOS_ENEM_2022.csv...
> -> 71340 linhas v√°lidas encontradas.
> Processando: MICRODADOS_ENEM_2023.csv...
> -> 74319 linhas v√°lidas encontradas.
>
> ‚úÖ ETL Conclu√≠do. DataFrame final criado com 204162 linhas.
> üíæ Dados limpos salvos em 'dados_ceara.csv'.
> ```

### Etapa 3: Ensinando o Computador a "Adivinhar" com k-NN

Agora chegamos √† parte mais interessante: como o modelo de Machine Learning realmente funciona? Usamos o algoritmo **k-Nearest Neighbors (k-NN)**, que √© surpreendentemente intuitivo.

#### Uma Analogia Simples para Entender o k-NN

Imagine que voc√™ quer prever o pre√ßo de uma casa, mas n√£o tem ideia de como fazer isso. Uma abordagem simples seria:
1.  Encontrar as **3 casas mais parecidas** com a sua na mesma vizinhan√ßa (com tamanho, n√∫mero de quartos e idade similares).
2.  Perguntar o pre√ßo de cada uma dessas 3 casas.
3.  Calcular a **m√©dia de pre√ßo** dessas 3 casas.
4.  Pronto! Essa m√©dia √© a sua "previs√£o" para o pre√ßo da sua casa.

O k-NN faz exatamente isso, mas para prever as notas do ENEM. Ele n√£o prev√™ o pre√ßo de uma casa, mas sim as notas de um aluno (`NU_NOTA_CN`, `NU_NOTA_MT`, etc.).

#### Como o k-NN Foi Implementado Neste Projeto?

1.  **Definindo os "Vizinhos" (as `COLUNAS_FEATURES`)**: Para o nosso modelo, um "vizinho" √© um outro estudante com um perfil socioecon√¥mico parecido. N√≥s dizemos ao algoritmo para comparar os alunos com base em caracter√≠sticas como:
    - `Q006`: A renda familiar.
    - `Q002`: A escolaridade da m√£e.
    - `TP_ESCOLA`: O tipo de escola (p√∫blica ou privada).

2.  **O "k" da Quest√£o (A Otimiza√ß√£o do Hiperpar√¢metro)**: Na nossa analogia, usamos 3 casas. Mas por que 3? Por que n√£o 5, 10 ou 20? Esse n√∫mero √© o `k`, e escolher o `k` certo √© fundamental.
    - Se `k` for **muito pequeno** (ex: `k=1`), o modelo fica "superespecialista". Ele baseia a previs√£o em um √∫nico vizinho, o que pode ser muito inst√°vel e levar a erros.
    - Se `k` for **muito grande** (ex: `k=100`), o modelo fica "gen√©rico demais". Ele considera tantos vizinhos que a previs√£o se torna uma m√©dia muito geral, perdendo as particularidades.

    A c√©lula **"Otimiza√ß√£o do Hiperpar√¢metro 'k'"** automatiza essa busca. Ela testa v√°rios valores para `k` (3, 5, 7, 9, etc.) e, para cada um, calcula o **Erro M√©dio Absoluto (MAE)**. O MAE nos diz, em m√©dia, qu√£o longe as previs√µes do modelo ficaram das notas reais. O valor de `k` que gerar o menor erro √© o campe√£o!

3.  **O Modelo em A√ß√£o (`KNeighborsRegressor`)**: A ferramenta que usamos para isso √© o `KNeighborsRegressor` do `scikit-learn`. O nome "Regressor" indica que ele serve para prever n√∫meros cont√≠nuos (como uma nota de 0 a 1000), e n√£o para classificar em categorias (como "aprovado" ou "reprovado").

```python
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
import time # Usaremos para dar uma sensa√ß√£o de progresso

def encontrar_melhor_k(df: pd.DataFrame, valores_k: list) -> int:
    """
    Testa diferentes valores de 'k' para o k-NN e retorna o que minimiza o erro,
    com prints detalhados do progresso.
    """
    print("\n--- üß† Buscando o melhor valor de 'k' para o k-NN ---")
    if df is None:
        print("‚ùå DataFrame de entrada √© inv√°lido. Abortando a otimiza√ß√£o.")
        return 0

    # 1. Preparando a busca pelo melhor valor de 'k'")
    
    X = pd.get_dummies(df[COLUNAS_FEATURES], drop_first=True)
    y = df[COLUNAS_ALVO]
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TAMANHO_TESTE, random_state=ESTADO_ALEATORIO
    )
    
    print("Iniciando os testes (esta etapa pode demorar)...")
    resultados_mae = {}
    for k in valores_k:
        # Print que mostra o in√≠cio do teste para um 'k' espec√≠fico
        print(f"   - Processando k = {k}...")
        
        # Estas s√£o as linhas que demoram:
        modelo = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)
        
        # C√°lculo do resultado
        mae_geral = mean_absolute_error(y_test, y_pred)
        resultados_mae[k] = mae_geral
        
        # Print que mostra o resultado parcial ao final de cada teste
        print(f"     -> Teste k={k} conclu√≠do! MAE Geral: {mae_geral:.4f}")

    # Prints finais
    melhor_k = min(resultados_mae, key=resultados_mae.get)
    print("\n   -> Todos os testes foram conclu√≠dos.")
    print(f"\n‚úÖ Otimiza√ß√£o Finalizada. Melhor valor encontrado: k = {melhor_k}")
    return melhor_k

# --- Execu√ß√£o da Fun√ß√£o ---
# Garante que os dados existem antes de rodar
if 'dados_limpos_ceara' in locals():
    valores_k_para_testar = [3, 5, 7, 9, 11, 13, 15, 17, 19]
    melhor_k = encontrar_melhor_k(dados_limpos_ceara, valores_k_para_testar)
else:
    print("‚ùå ERRO: A vari√°vel 'dados_limpos_ceara' n√£o foi encontrada. Execute a c√©lula de ETL primeiro.")
```
> **Sa√≠da:**
> ```
> --- üß† Buscando o melhor valor de 'k' para o k-NN ---
> Iniciando os testes (esta etapa pode demorar)...
>    - Processando k = 3...
>      -> Teste k=3 conclu√≠do! MAE Geral: 95.0777
>    - Processando k = 5...
>      -> Teste k=5 conclu√≠do! MAE Geral: 96.2481
>    - Processando k = 7...
>      -> Teste k=7 conclu√≠do! MAE Geral: 92.9195
>    - Processando k = 9...
>      -> Teste k=9 conclu√≠do! MAE Geral: 90.2997
>    - Processando k = 11...
>      -> Teste k=11 conclu√≠do! MAE Geral: 89.7812
>    - Processando k = 13...
>      -> Teste k=13 conclu√≠do! MAE Geral: 88.5116
>    - Processando k = 15...
>      -> Teste k=15 conclu√≠do! MAE Geral: 88.0135
>    - Processando k = 17...
>      -> Teste k=17 conclu√≠do! MAE Geral: 88.0067
>    - Processando k = 19...
>      -> Teste k=19 conclu√≠do! MAE Geral: 87.9317
>
>    -> Todos os testes foram conclu√≠dos.
>
> ‚úÖ Otimiza√ß√£o Finalizada. Melhor valor encontrado: k = 19
> ```

### Etapa 4: Treinamento e Salvamento do Modelo Final

Depois de descobrir o melhor valor de `k`, estamos prontos para a etapa final.
1.  **Treinamento**: N√≥s treinamos o modelo `KNeighborsRegressor` uma √∫ltima vez, usando o `k` otimizado e nosso conjunto de dados limpos.
2.  **Salvamento**: Ao final, geramos dois arquivos cruciais:
    - `modelo_knn.joblib`: Este √© o nosso **modelo treinado**, como se fosse o "c√©rebro" do nosso sistema, pronto para fazer novas previs√µes.
    - `colunas_modelo.json`: Este √© o **"manual de instru√ß√µes"** do modelo. Ele guarda a lista exata de colunas (e a ordem delas) que o modelo precisa receber para funcionar corretamente.

Com esses dois arquivos, podemos facilmente carregar nosso modelo em outra aplica√ß√£o (como um site ou um dashboard) para prever as notas de novos alunos sem precisar rodar todo o processo de limpeza e treinamento novamente.

```python
def treinar_e_salvar_modelo_final(df: pd.DataFrame, k: int):
    """
    Treina o modelo k-NN com o valor de 'k' otimizado e salva os artefatos.
    """
    print(f"\n--- üöÇ Treinando e salvando o modelo final com k = {k} ---")
    if df is None or k == 0:
        print("‚ùå Dados ou valor de 'k' inv√°lidos. Abortando treinamento.")
        return

    X = pd.get_dummies(df[COLUNAS_FEATURES], drop_first=True)
    y = df[COLUNAS_ALVO]
    
    # Dica: O modelo final pode ser treinado com todos os dados, mas para manter
    # a consist√™ncia do projeto, vamos usar o mesmo split.
    X_train, _, y_train, _ = train_test_split(
        X, y, test_size=TAMANHO_TESTE, random_state=ESTADO_ALEATORIO
    )

    modelo_final = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)
    modelo_final.fit(X_train, y_train)

    joblib.dump(modelo_final, ARQUIVO_MODELO)
    with open(ARQUIVO_COLUNAS, 'w') as f:
        json.dump(X.columns.tolist(), f)

    print(f"‚úÖ Modelo final treinado com sucesso!")
    print(f"üíæ Modelo salvo em: '{ARQUIVO_MODELO}'")
    print(f"üíæ Colunas salvas em: '{ARQUIVO_COLUNAS}'")
    print("\n--- üöÄ PROJETO CONCLU√çDO ---")

# Executa o treinamento final com o melhor 'k' encontrado
treinar_e_salvar_modelo_final(dados_limpos_ceara, melhor_k)
```
> **Sa√≠da:**
> ```
> --- üöÇ Treinando e salvando o modelo final com k = 19 ---
> ‚úÖ Modelo final treinado com sucesso!
> üíæ Modelo salvo em: 'modelo_knn.joblib'
> üíæ Colunas salvas em: 'colunas_modelo.json'
>
> --- üéâ PROJETO FINALIZADO ---
> ```

## ‚ú® Sess√£o B√¥nus: A Aplica√ß√£o Pr√°tica em um Dashboard Interativo

Ap√≥s todo o trabalho de limpeza, otimiza√ß√£o e treinamento, o produto final n√£o √© apenas o c√≥digo, mas o modelo salvo (modelo_knn.joblib) e seu manual (colunas_modelo.json), prontos para serem usados.

O Dashboard interativo √© a prova de conceito de que nosso modelo funciona na pr√°tica. Ele permite que qualquer pessoa interaja com o "c√©rebro" do Machine Learning que acabamos de criar.

## üìä Objetivo do Dashboard
O objetivo √© transformar a l√≥gica complexa do nosso c√≥digo Python em uma ferramenta acess√≠vel e visual. O dashboard, implementado no arquivo dashboard.py (em anexo no reposit√≥rio), faz o seguinte:

- Carrega o Modelo e o Manual: Ele usa o joblib para carregar o modelo_knn.joblib e o json para carregar as colunas necess√°rias.  

- Coleta o Perfil do Usu√°rio: Ele apresenta widgets simples para o usu√°rio informar suas caracter√≠sticas socioecon√¥micas (Q006, Q002, TP_ESCOLA, etc.) ‚Äì exatamente as COLUNAS_FEATURES que o modelo espera.  

- Realiza a Previs√£o: Ele insere as informa√ß√µes do usu√°rio no modelo e recebe as notas previstas nas cinco √°reas do conhecimento (COLUNAS_ALVO).  

- Exibe os Resultados: Ele apresenta as notas previstas de forma clara e visual, provando que o processo de ponta a ponta (ETL, Treinamento, Produ√ß√£o) foi bem-sucedido.  

## üé® Sobre o Streamlit
Para construir o dashboard, utilizamos a biblioteca Streamlit.

O Streamlit √© uma ferramenta de c√≥digo aberto que permite transformar scripts de an√°lise de dados e Machine Learning em aplicativos da web interativos e bonitos com pouqu√≠ssimas linhas de c√≥digo. √â a solu√ß√£o perfeita para demonstrar o potencial do nosso modelo sem a necessidade de aprender tecnologias complexas de desenvolvimento web (como HTML, CSS e JavaScript). Ele lida com a interatividade, o layout e a implanta√ß√£o de forma quase m√°gica.  

## üîó Veja o Modelo em A√ß√£o
Voc√™ pode interagir e testar o poder de previs√£o do modelo k-NN treinado neste projeto atrav√©s do link de implanta√ß√£o:  

[Veja o projeto clicando aqui!](https://projetos-262dc3bahjdyph3gmfuexf.streamlit.app/)

## üßë‚Äçüíª Autor

Projeto criado por **[Weillon Mota]**  
üì´ [weillonmota@gmail.com]  
üîó [linkedin.com/in/weillonmota](https://linkedin.com/in/weillonmota)
