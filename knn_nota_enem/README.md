# ğŸ¤– Prevendo Notas do ENEM com Machine Learning

Bem-vindo! Este projeto Ã© um guia prÃ¡tico que demonstra como usar dados para treinar um modelo de Machine Learning capaz de prever as notas de um estudante no ENEM. Utilizamos uma tÃ©cnica chamada **k-Nearest Neighbors (k-NN)**, ou "k-Vizinhos Mais PrÃ³ximos", para realizar essa tarefa.

O objetivo Ã© criar um material didÃ¡tico, explicando cada passo do processo de forma clara e simples, desde a coleta dos dados brutos atÃ© o salvamento de um modelo pronto para uso.

## ğŸ“‚ Estrutura do Projeto

O cÃ³digo estÃ¡ organizado em um notebook Jupyter (`etl.ipynb`) e dividido em quatro etapas principais:

1.  **ConfiguraÃ§Ã£o**: Onde preparamos nosso ambiente e definimos as regras do jogo.
2.  **ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga)**: A fase de "faxina", onde limpamos e organizamos os dados.
3.  **OtimizaÃ§Ã£o do k-NN**: O coraÃ§Ã£o do projeto, onde ensinamos o modelo a aprender com os dados.
4.  **Treinamento Final**: Onde consolidamos o aprendizado e salvamos nosso modelo inteligente.

---
## ğŸ¤” Como o Programa Funciona? Um Guia Passo a Passo

### Etapa 1: ConfiguraÃ§Ã£o e Constantes

Antes de comeÃ§ar qualquer projeto de programaÃ§Ã£o, Ã© uma boa prÃ¡tica organizar as ferramentas. Nesta primeira cÃ©lula do cÃ³digo, Ã© preciso:
- **Importamos as bibliotecas**: Ferramentas como `pandas` (para mexer com tabelas) e `scikit-learn` (para Machine Learning).
- **Centralizamos as informaÃ§Ãµes**: Definimos nomes de arquivos e colunas em um Ãºnico lugar. Isso Ã© como ter uma "lista de compras" antes de ir ao mercado e se precisarmos mudar algo, sabemos exatamente onde olhar.

```python
# ImportaÃ§Ã£o de bibliotecas essenciais
import pandas as pd
import joblib
import json
import os
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error

# --- ARQUIVOS E CAMINHOS ---
ARQUIVOS_ENEM = ['MICRODADOS_ENEM_2021.csv', 'MICRODADOS_ENEM_2022.csv', 'MICRODADOS_ENEM_2023.csv']
ARQUIVO_DADOS_CEARA = 'dados_ceara.csv'
ARQUIVO_MODELO = 'modelo_knn.joblib'
ARQUIVO_COLUNAS = 'colunas_modelo.json'

# --- COLUNAS DO DATASET ---
# Colunas que serÃ£o o alvo da nossa previsÃ£o (target)
COLUNAS_ALVO = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']
# Colunas que usaremos para fazer a previsÃ£o (features)
COLUNAS_FEATURES = ['Q006', 'Q002', 'TP_ESCOLA', 'TP_COR_RACA', 'SG_UF_ESC']
# Lista completa de colunas a serem lidas dos arquivos originais
COLUNAS_DESEJADAS = ['NU_ANO'] + COLUNAS_ALVO + COLUNAS_FEATURES

# --- PARÃ‚METROS DO MODELO ---
ESTADO_ALEATORIO = 42 # Garante que a divisÃ£o dos dados seja sempre a mesma
TAMANHO_TESTE = 0.2  # Define que 20% dos dados serÃ£o usados para teste

print("âœ… MÃ³dulo de ConfiguraÃ§Ã£o carregado com sucesso!")
```
> **SaÃ­da:**
> ```
> âœ… MÃ³dulo de ConfiguraÃ§Ã£o carregado com sucesso!
> ```

### Etapa 2: A Faxina dos Dados (ETL)

Os dados brutos do ENEM sÃ£o gigantescos e um pouco bagunÃ§ados. Para que nosso modelo consiga aprender algo Ãºtil, precisamos primeiro organizar a casa. O processo de ETL faz exatamente isso:

1.  **Extrair**: Lemos os arquivos CSV do ENEM (`MICRODADOS_ENEM_2021.csv`, etc.). Para nÃ£o sobrecarregar a memÃ³ria do computador, pegamos apenas as colunas que nos interessam.
2.  **Transformar**: Aqui acontece a mÃ¡gica da limpeza. NÃ³s:
    - Removemos todas as linhas que tÃªm alguma informaÃ§Ã£o faltando (como uma nota em branco).
    - Filtramos os dados para manter apenas os registros de estudantes do CearÃ¡ (`CE`).
3.  **Carregar**: Juntamos todos os dados limpos de diferentes anos em uma Ãºnica tabela e a salvamos como `dados_ceara.csv`. Ter esse arquivo limpo economiza muito tempo, pois nÃ£o precisamos repetir essa faxina toda vez que rodamos o projeto.


```python
def executar_etl(lista_arquivos: list, colunas: list, estado_filtro: str = 'CE') -> pd.DataFrame | None:
    """
    LÃª, limpa, filtra e combina mÃºltiplos arquivos CSV do ENEM.
    - ExtraÃ§Ã£o: LÃª apenas as colunas desejadas para otimizar o uso de memÃ³ria.
    - TransformaÃ§Ã£o: Remove linhas com dados faltantes e filtra pelo estado.
    - Carga: Consolida os dados de todos os arquivos em um Ãºnico DataFrame.
    """
    print(f"\n--- ğŸš€ Iniciando processo de ETL para o estado: {estado_filtro} ---")
    dataframes = []

    for arquivo in lista_arquivos:
        if not os.path.exists(arquivo):
            print(f"âš ï¸ AVISO: Arquivo '{arquivo}' nÃ£o encontrado. Pulando...")
            continue
        try:
            print(f"Processando: {arquivo}...")
            df = pd.read_csv(arquivo, sep=';', encoding='latin-1', usecols=colunas)
            df.dropna(inplace=True)
            df_estado = df[df['SG_UF_ESC'] == estado_filtro]
            if not df_estado.empty:
                dataframes.append(df_estado)
                print(f"-> {len(df_estado)} linhas vÃ¡lidas encontradas.")
            else:
                print("-> Nenhuma linha vÃ¡lida para o CearÃ¡ neste arquivo.")
        except Exception as e:
            print(f"âŒ ERRO inesperado ao processar '{arquivo}': {e}")

    if not dataframes:
        print("\nâŒ ETL falhou. Nenhum DataFrame foi processado.")
        return None

    df_final = pd.concat(dataframes, ignore_index=True)
    print(f"\nâœ… ETL ConcluÃ­do. DataFrame final criado com {len(df_final)} linhas.")
    df_final.to_csv(ARQUIVO_DADOS_CEARA, index=False)
    print(f"ğŸ’¾ Dados limpos salvos em '{ARQUIVO_DADOS_CEARA}'.")
    return df_final

# Executa a funÃ§Ã£o
dados_limpos_ceara = executar_etl(lista_arquivos=ARQUIVOS_ENEM, colunas=COLUNAS_DESEJADAS)
```
> **SaÃ­da:**
> ```
> --- ğŸš€ Iniciando processo de ETL para o estado: CE ---
> Processando: MICRODADOS_ENEM_2021.csv...
> -> 58503 linhas vÃ¡lidas encontradas.
> Processando: MICRODADOS_ENEM_2022.csv...
> -> 71340 linhas vÃ¡lidas encontradas.
> Processando: MICRODADOS_ENEM_2023.csv...
> -> 74319 linhas vÃ¡lidas encontradas.
>
> âœ… ETL ConcluÃ­do. DataFrame final criado com 204162 linhas.
> ğŸ’¾ Dados limpos salvos em 'dados_ceara.csv'.
> ```

### Etapa 3: Ensinando o Computador a "Adivinhar" com k-NN

Agora chegamos Ã  parte mais interessante: como o modelo de Machine Learning realmente funciona? Usamos o algoritmo **k-Nearest Neighbors (k-NN)**, que Ã© surpreendentemente intuitivo.

#### Uma Analogia Simples para Entender o k-NN

Imagine que vocÃª quer prever o preÃ§o de uma casa, mas nÃ£o tem ideia de como fazer isso. Uma abordagem simples seria:
1.  Encontrar as **3 casas mais parecidas** com a sua na mesma vizinhanÃ§a (com tamanho, nÃºmero de quartos e idade similares).
2.  Perguntar o preÃ§o de cada uma dessas 3 casas.
3.  Calcular a **mÃ©dia de preÃ§o** dessas 3 casas.
4.  Pronto! Essa mÃ©dia Ã© a sua "previsÃ£o" para o preÃ§o da sua casa.

O k-NN faz exatamente isso, mas para prever as notas do ENEM. Ele nÃ£o prevÃª o preÃ§o de uma casa, mas sim as notas de um aluno (`NU_NOTA_CN`, `NU_NOTA_MT`, etc.).

#### Como o k-NN Foi Implementado Neste Projeto?

1.  **Definindo os "Vizinhos" (as `COLUNAS_FEATURES`)**: Para o nosso modelo, um "vizinho" Ã© um outro estudante com um perfil socioeconÃ´mico parecido. NÃ³s dizemos ao algoritmo para comparar os alunos com base em caracterÃ­sticas como:
    - `Q006`: A renda familiar.
    - `Q002`: A escolaridade da mÃ£e.
    - `TP_ESCOLA`: O tipo de escola (pÃºblica ou privada).

2.  **O "k" da QuestÃ£o (A OtimizaÃ§Ã£o do HiperparÃ¢metro)**: Na nossa analogia, usamos 3 casas. Mas por que 3? Por que nÃ£o 5, 10 ou 20? Esse nÃºmero Ã© o `k`, e escolher o `k` certo Ã© fundamental.
    - Se `k` for **muito pequeno** (ex: `k=1`), o modelo fica "superespecialista". Ele baseia a previsÃ£o em um Ãºnico vizinho, o que pode ser muito instÃ¡vel e levar a erros.
    - Se `k` for **muito grande** (ex: `k=100`), o modelo fica "genÃ©rico demais". Ele considera tantos vizinhos que a previsÃ£o se torna uma mÃ©dia muito geral, perdendo as particularidades.

    A cÃ©lula **"OtimizaÃ§Ã£o do HiperparÃ¢metro 'k'"** automatiza essa busca. Ela testa vÃ¡rios valores para `k` (3, 5, 7, 9, etc.) e, para cada um, calcula o **Erro MÃ©dio Absoluto (MAE)**. O MAE nos diz, em mÃ©dia, quÃ£o longe as previsÃµes do modelo ficaram das notas reais. O valor de `k` que gerar o menor erro Ã© o campeÃ£o!

3.  **O Modelo em AÃ§Ã£o (`KNeighborsRegressor`)**: A ferramenta que usamos para isso Ã© o `KNeighborsRegressor` do `scikit-learn`. O nome "Regressor" indica que ele serve para prever nÃºmeros contÃ­nuos (como uma nota de 0 a 1000), e nÃ£o para classificar em categorias (como "aprovado" ou "reprovado").

```python
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
import time # Usaremos para dar uma sensaÃ§Ã£o de progresso

def encontrar_melhor_k(df: pd.DataFrame, valores_k: list) -> int:
    """
    Testa diferentes valores de 'k' para o k-NN e retorna o que minimiza o erro,
    com prints detalhados do progresso.
    """
    print("\n--- ğŸ§  Buscando o melhor valor de 'k' para o k-NN ---")
    if df is None:
        print("âŒ DataFrame de entrada Ã© invÃ¡lido. Abortando a otimizaÃ§Ã£o.")
        return 0

    # 1. Preparando a busca pelo melhor valor de 'k'")
    
    X = pd.get_dummies(df[COLUNAS_FEATURES], drop_first=True)
    y = df[COLUNAS_ALVO]
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TAMANHO_TESTE, random_state=ESTADO_ALEATORIO
    )
    
    print("Iniciando os testes (esta etapa pode demorar)...")
    resultados_mae = {}
    for k in valores_k:
        # Print que mostra o inÃ­cio do teste para um 'k' especÃ­fico
        print(f"   - Processando k = {k}...")
        
        # Estas sÃ£o as linhas que demoram:
        modelo = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)
        
        # CÃ¡lculo do resultado
        mae_geral = mean_absolute_error(y_test, y_pred)
        resultados_mae[k] = mae_geral
        
        # Print que mostra o resultado parcial ao final de cada teste
        print(f"     -> Teste k={k} concluÃ­do! MAE Geral: {mae_geral:.4f}")

    # Prints finais
    melhor_k = min(resultados_mae, key=resultados_mae.get)
    print("\n   -> Todos os testes foram concluÃ­dos.")
    print(f"\nâœ… OtimizaÃ§Ã£o Finalizada. Melhor valor encontrado: k = {melhor_k}")
    return melhor_k

# --- ExecuÃ§Ã£o da FunÃ§Ã£o ---
# Garante que os dados existem antes de rodar
if 'dados_limpos_ceara' in locals():
    valores_k_para_testar = [3, 5, 7, 9, 11, 13, 15, 17, 19]
    melhor_k = encontrar_melhor_k(dados_limpos_ceara, valores_k_para_testar)
else:
    print("âŒ ERRO: A variÃ¡vel 'dados_limpos_ceara' nÃ£o foi encontrada. Execute a cÃ©lula de ETL primeiro.")
```
> **SaÃ­da:**
> ```
> --- ğŸ§  Buscando o melhor valor de 'k' para o k-NN ---
> Iniciando os testes (esta etapa pode demorar)...
>    - Processando k = 3...
>      -> Teste k=3 concluÃ­do! MAE Geral: 95.0777
>    - Processando k = 5...
>      -> Teste k=5 concluÃ­do! MAE Geral: 96.2481
>    - Processando k = 7...
>      -> Teste k=7 concluÃ­do! MAE Geral: 92.9195
>    - Processando k = 9...
>      -> Teste k=9 concluÃ­do! MAE Geral: 90.2997
>    - Processando k = 11...
>      -> Teste k=11 concluÃ­do! MAE Geral: 89.7812
>    - Processando k = 13...
>      -> Teste k=13 concluÃ­do! MAE Geral: 88.5116
>    - Processando k = 15...
>      -> Teste k=15 concluÃ­do! MAE Geral: 88.0135
>    - Processando k = 17...
>      -> Teste k=17 concluÃ­do! MAE Geral: 88.0067
>    - Processando k = 19...
>      -> Teste k=19 concluÃ­do! MAE Geral: 87.9317
>
>    -> Todos os testes foram concluÃ­dos.
>
> âœ… OtimizaÃ§Ã£o Finalizada. Melhor valor encontrado: k = 19
> ```

### Etapa 4: Treinamento e Salvamento do Modelo Final

Depois de descobrir o melhor valor de `k`, estamos prontos para a etapa final.
1.  **Treinamento**: NÃ³s treinamos o modelo `KNeighborsRegressor` uma Ãºltima vez, usando o `k` otimizado e nosso conjunto de dados limpos.
2.  **Salvamento**: Ao final, geramos dois arquivos cruciais:
    - `modelo_knn.joblib`: Este Ã© o nosso **modelo treinado**, como se fosse o "cÃ©rebro" do nosso sistema, pronto para fazer novas previsÃµes.
    - `colunas_modelo.json`: Este Ã© o **"manual de instruÃ§Ãµes"** do modelo. Ele guarda a lista exata de colunas (e a ordem delas) que o modelo precisa receber para funcionar corretamente.

Com esses dois arquivos, podemos facilmente carregar nosso modelo em outra aplicaÃ§Ã£o (como um site ou um dashboard) para prever as notas de novos alunos sem precisar rodar todo o processo de limpeza e treinamento novamente.

```python
def treinar_e_salvar_modelo_final(df: pd.DataFrame, k: int):
    """
    Treina o modelo k-NN com o valor de 'k' otimizado e salva os artefatos.
    """
    print(f"\n--- ğŸš‚ Treinando e salvando o modelo final com k = {k} ---")
    if df is None or k == 0:
        print("âŒ Dados ou valor de 'k' invÃ¡lidos. Abortando treinamento.")
        return

    X = pd.get_dummies(df[COLUNAS_FEATURES], drop_first=True)
    y = df[COLUNAS_ALVO]
    
    # Dica: O modelo final pode ser treinado com todos os dados, mas para manter
    # a consistÃªncia do projeto, vamos usar o mesmo split.
    X_train, _, y_train, _ = train_test_split(
        X, y, test_size=TAMANHO_TESTE, random_state=ESTADO_ALEATORIO
    )

    modelo_final = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)
    modelo_final.fit(X_train, y_train)

    joblib.dump(modelo_final, ARQUIVO_MODELO)
    with open(ARQUIVO_COLUNAS, 'w') as f:
        json.dump(X.columns.tolist(), f)

    print(f"âœ… Modelo final treinado com sucesso!")
    print(f"ğŸ’¾ Modelo salvo em: '{ARQUIVO_MODELO}'")
    print(f"ğŸ’¾ Colunas salvas em: '{ARQUIVO_COLUNAS}'")
    print("\n--- ğŸš€ PROJETO CONCLUÃDO ---")

# Executa o treinamento final com o melhor 'k' encontrado
treinar_e_salvar_modelo_final(dados_limpos_ceara, melhor_k)
```
> **SaÃ­da:**
> ```
> --- ğŸš‚ Treinando e salvando o modelo final com k = 19 ---
> âœ… Modelo final treinado com sucesso!
> ğŸ’¾ Modelo salvo em: 'modelo_knn.joblib'
> ğŸ’¾ Colunas salvas em: 'colunas_modelo.json'
>
> --- ğŸ‰ PROJETO FINALIZADO ---
> ```

## âœ¨ SessÃ£o BÃ´nus: AplicaÃ§Ã£o PrÃ¡tica em um Dashboard Interativo  

ApÃ³s todo o trabalho de limpeza, otimizaÃ§Ã£o e treinamento, o produto final nÃ£o Ã© apenas o cÃ³digo, mas o modelo salvo (`modelo_knn.joblib`) e seu manual (`colunas_modelo.json`), prontos para serem usados.

O Dashboard interativo Ã© a prova de conceito de que nosso modelo funciona na prÃ¡tica. Ele permite que qualquer pessoa interaja com o "cÃ©rebro" do Machine Learning que acabamos de criar.

## ğŸ“Š Objetivo do Dashboard  
O objetivo Ã© transformar a lÃ³gica complexa do nosso cÃ³digo Python em uma ferramenta acessÃ­vel e visual. O dashboard, implementado no arquivo `dashboard.py` (em anexo no repositÃ³rio), faz o seguinte:

- Carrega o Modelo e o Manual: Ele usa o `joblib` para carregar o `modelo_knn.joblib` e o `json` para carregar as colunas necessÃ¡rias.  

- Coleta o Perfil do UsuÃ¡rio: Ele apresenta widgets simples para o usuÃ¡rio informar suas caracterÃ­sticas socioeconÃ´micas (`Q006`, `Q002`, `TP_ESCOLA`, etc.) â€“ exatamente as `COLUNAS_FEATURES` que o modelo espera.  

- Realiza a PrevisÃ£o: Ele insere as informaÃ§Ãµes do usuÃ¡rio no modelo e recebe as notas previstas nas cinco Ã¡reas do conhecimento (`COLUNAS_ALVO`).  

- Exibe os Resultados: Ele apresenta as notas previstas de forma clara e visual, provando que o processo de ponta a ponta (ETL, Treinamento, ProduÃ§Ã£o) foi bem-sucedido.  

## ğŸ¨ Sobre o Streamlit  
Para construir o dashboard, utilizamos a biblioteca Streamlit.

O Streamlit Ã© uma ferramenta de cÃ³digo aberto que permite transformar scripts de anÃ¡lise de dados e Machine Learning em aplicativos da web interativos e bonitos com pouquÃ­ssimas linhas de cÃ³digo. Ã‰ a soluÃ§Ã£o perfeita para demonstrar o potencial do nosso modelo sem a necessidade de aprender tecnologias complexas de desenvolvimento web (como HTML, CSS e JavaScript). Ele lida com a interatividade, o layout e a implantaÃ§Ã£o de forma quase mÃ¡gica.  

## ğŸ¯ Veja o Modelo em AÃ§Ã£o  
VocÃª pode interagir e testar o poder de previsÃ£o do modelo k-NN treinado neste projeto atravÃ©s do link de implantaÃ§Ã£o:  

ğŸ‘‰[Veja o projeto clicando aqui!](https://projetos-262dc3bahjdyph3gmfuexf.streamlit.app/)

## ğŸš€ ConclusÃ£o  
Este projeto transforma dados brutos em inteligÃªncia acionÃ¡vel. Seguindo estes passos, construÃ­mos um sistema que aprendeu a encontrar padrÃµes no perfil dos estudantes e, com base neles, fazer previsÃµes sobre seu desempenho no ENEM. O uso do k-NN mostra como conceitos de "similaridade" e "vizinhanÃ§a" podem ser ferramentas poderosas no mundo do Machine Learning.

## ğŸ§‘â€ğŸ’» Autor

Projeto criado por **[Weillon Mota]**  
ğŸ“« [weillonmota@gmail.com]  
ğŸ”— [linkedin.com/in/weillonmota](https://linkedin.com/in/weillonmota)
